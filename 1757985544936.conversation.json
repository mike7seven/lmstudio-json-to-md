{
  "name": "Capital of France",
  "pinned": false,
  "createdAt": 1757985544937,
  "preset": "@local:no-think",
  "tokenCount": 33,
  "systemPrompt": "",
  "messages": [
    {
      "versions": [
        {
          "type": "singleStep",
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": "What is the capital of France? "
            }
          ],
          "preprocessed": {
            "role": "user",
            "content": [
              {
                "type": "text",
                "text": "What is the capital of France? "
              }
            ]
          },
          "edited": true
        }
      ],
      "currentlySelected": 0
    },
    {
      "versions": [
        {
          "type": "multiStep",
          "role": "assistant",
          "steps": [
            {
              "type": "contentBlock",
              "stepIdentifier": "1757985639279-0.5680650518798477",
              "content": [
                {
                  "type": "text",
                  "text": "\n\nThe capital of France is **Paris**.",
                  "fromDraftModel": false,
                  "tokensCount": 10,
                  "isStructural": false
                }
              ],
              "defaultShouldIncludeInContext": true,
              "shouldIncludeInContext": true,
              "genInfo": {
                "indexedModelIdentifier": "Qwen/Qwen3-30B-A3B-MLX-bf16",
                "identifier": "qwen3-30b-a3b-mlx",
                "loadModelConfig": {
                  "fields": [
                    {
                      "key": "llm.load.contextLength",
                      "value": 40960
                    },
                    {
                      "key": "llm.load.mlx.kvCacheQuantization",
                      "value": {
                        "enabled": true,
                        "bits": 8,
                        "groupSize": 64,
                        "quantizedStart": 5000
                      }
                    }
                  ]
                },
                "predictionConfig": {
                  "fields": [
                    {
                      "key": "llm.prediction.promptTemplate",
                      "value": {
                        "type": "jinja",
                        "jinjaPromptTemplate": {
                          "template": "{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0].role == 'system' %}\n        {{- messages[0].content + '\\n\\n' }}\n    {%- endif %}\n    {{- \"# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0].role == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0].content + '<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\n{%- for index in range(ns.last_query_index, -1, -1) %}\n    {%- set message = messages[index] %}\n    {%- if ns.multi_step_tool and message.role == \"user\" and not('<tool_response>' in message.content and '</tool_response>' in message.content) %}\n        {%- set ns.multi_step_tool = false %}\n        {%- set ns.last_query_index = index %}\n    {%- endif %}\n{%- endfor %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {%- set content = message.content %}\n        {%- set reasoning_content = '' %}\n        {%- if message.reasoning_content is defined and message.reasoning_content is not none %}\n            {%- set reasoning_content = message.reasoning_content %}\n        {%- else %}\n            {%- if '</think>' in message.content %}\n                {%- set content = message.content.split('</think>')[-1].lstrip('\\n') %}\n                {%- set reasoning_content = message.content.split('</think>')[0].rstrip('\\n').split('<think>')[-1].lstrip('\\n') %}\n            {%- endif %}\n        {%- endif %}\n        {%- if loop.index0 > ns.last_query_index %}\n            {%- if loop.last or (not loop.last and reasoning_content) %}\n                {{- '<|im_start|>' + message.role + '\\n<think>\\n' + reasoning_content.strip('\\n') + '\\n</think>\\n\\n' + content.lstrip('\\n') }}\n            {%- else %}\n                {{- '<|im_start|>' + message.role + '\\n' + content }}\n            {%- endif %}\n        {%- else %}\n            {{- '<|im_start|>' + message.role + '\\n' + content }}\n        {%- endif %}\n        {%- if message.tool_calls %}\n            {%- for tool_call in message.tool_calls %}\n                {%- if (loop.first and content) or (not loop.first) %}\n                    {{- '\\n' }}\n                {%- endif %}\n                {%- if tool_call.function %}\n                    {%- set tool_call = tool_call.function %}\n                {%- endif %}\n                {{- '<tool_call>\\n{\"name\": \"' }}\n                {{- tool_call.name }}\n                {{- '\", \"arguments\": ' }}\n                {%- if tool_call.arguments is string %}\n                    {{- tool_call.arguments }}\n                {%- else %}\n                    {{- tool_call.arguments | tojson }}\n                {%- endif %}\n                {{- '}\\n</tool_call>' }}\n            {%- endfor %}\n        {%- endif %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n    {%- if enable_thinking is defined and enable_thinking is false %}\n        {{- '<think>\\n\\n</think>\\n\\n' }}\n    {%- endif %}\n{%- endif %}"
                        },
                        "stopStrings": []
                      }
                    },
                    {
                      "key": "llm.prediction.topPSampling",
                      "value": {
                        "checked": false,
                        "value": 1
                      }
                    },
                    {
                      "key": "llm.prediction.minPSampling",
                      "value": {
                        "checked": false,
                        "value": 0
                      }
                    },
                    {
                      "key": "llm.prediction.repeatPenalty",
                      "value": {
                        "checked": true,
                        "value": 1.1
                      }
                    },
                    {
                      "key": "llm.prediction.topKSampling",
                      "value": 100
                    },
                    {
                      "key": "llm.prediction.tools",
                      "value": {
                        "type": "none"
                      }
                    }
                  ]
                },
                "stats": {
                  "stopReason": "eosFound",
                  "tokensPerSecond": 65.39717025790323,
                  "numGpuLayers": -1,
                  "timeToFirstTokenSec": 0.277,
                  "totalTimeSec": 0.214,
                  "promptTokensCount": 24,
                  "predictedTokensCount": 14,
                  "totalTokensCount": 38
                }
              }
            },
            {
              "type": "debugInfoBlock",
              "stepIdentifier": "1757985639397-0.881322284824169",
              "debugInfo": "Conversation naming technique: 'prompt'"
            }
          ],
          "senderInfo": {
            "senderName": "qwen3-30b-a3b-mlx"
          }
        }
      ],
      "currentlySelected": 0
    }
  ],
  "usePerChatPredictionConfig": true,
  "perChatPredictionConfig": {
    "fields": [
      {
        "key": "llm.prediction.systemPrompt",
        "value": "/no_think"
      },
      {
        "key": "ext.virtualModel.customField.qwen.qwen330bA3b.enableThinking",
        "value": false
      }
    ]
  },
  "clientInput": "",
  "clientInputFiles": [],
  "userFilesSizeBytes": 0,
  "lastUsedModel": {
    "identifier": "qwen3-30b-a3b-mlx",
    "indexedModelIdentifier": "Qwen/Qwen3-30B-A3B-MLX-bf16",
    "instanceLoadTimeConfig": {
      "fields": []
    },
    "instanceOperationTimeConfig": {
      "fields": []
    }
  },
  "notes": [],
  "plugins": [
    "lmstudio/rag-v1"
  ],
  "pluginConfigs": {},
  "disabledPluginTools": [],
  "looseFiles": []
}